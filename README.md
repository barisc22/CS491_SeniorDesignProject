# MoveIt: Indoor Manipulation
![Project Specifications](bullion-hop-cones.jpg)
<br>
<br>
Project Reports:
<br>
<br>
Project Specifications:
<a href="https://github.com/barisc22/CS491_SeniorDesignProject/raw/master/project_specifications_report.pdf" title="Project Specifications">Project Specifications</a>
<br>
<br>
Analysis Report:
<a href="https://github.com/barisc22/CS491_SeniorDesignProject/raw/master/analysis_report.pdf" title="Analysis Report">Analysis Report</a>
<br>
<br>
Design Report:
<a href="https://github.com/barisc22/CS491_SeniorDesignProject/raw/master/design_report.pdf" title="Design Report">Design Report</a>
<br>
<br>
Low Level Design Report:
<a href="https://github.com/barisc22/MoveIt/blob/master/Low-Level_Design_Report.pdf" title="Design Report">Low Level Design Report</a>
<br>
<br>
Final Report:
<a href="https://github.com/barisc22/MoveIt/blob/master/Final_Report.pdf" title="Design Report">Final Report</a>
<br>
<br>
Project Members:
Pınar Ayaz,
Barış Can,
Faruk Oruç,
Ünsal Öztürk,
Mert Soydinç
<br>
<br>
Project MoveIt: Indoor Manipulation aims to develop an application which will semantically reconstruct the geometry of indoor areas, such as a living room or a kitchen, in 3D by using videos, live scans/feed obtained from the camera of a mobile device. The 3D reconstruction process will produce a 3D scene and will label the reconstructed objects and geometry semantically by attaching a semantic label to each object. It will also allow the users of the application to manipulate the scene by allowing the users to move, rotate, scale, and deform the geometry of the objects. Texture obtained from the live feed will also be mapped to the corresponding meshes. The application will store the 3D reconstruction information along with the texture, label, and mesh information of a given object on a database for later data analytics and machine learning purposes, and will be open to the public as a labelled set of 3D objects, which may be suitable for supervised learning purposes.
